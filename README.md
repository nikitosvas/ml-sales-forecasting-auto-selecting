
# Алгоритм работы проекта прогнозирования продаж

Данный проект предназначен для прогнозирования финансовых показателей 
по каждому каналу продаж до конца месяца с автоматическим выбором модели и параметров обучения.

В системе реализовано:


- сравнение baseline и ML ВЫБРАННЫХ моделей
- подбор оптимального окна обучения  
- рекурсивный и direct прогноз 
- бэктестирование на нескольких периодах  
- автоматический выбор лучшей модели  
- сохранение model policy в JSON  
- использование policy в последующем production-прогнозе  
---

# 1. Общая архитектура пайплайна

Pipeline состоит из двух шагов:

## 1.1 Шаг обучения (Backtest + Model Selection)

Используется для подбора моделей и параметров:

1. Загрузка исторических ПРЕДАГРЕГИРОВАННЫХ данных из БД CH 
2. Подготовка long-формата таблицы 
3. Генерация календарных и lag фичей  
4. Прогон нескольких моделей  
5. Тестирование разных train windows (30, 60, 90, 120 ...)
6. Расчёт метрик качества. Здесь регрессионные метрики (RMSE, WMAPE, ...) 
7. Определение лучшей модели по результатам тестов 
8. Сохранение policy в JSON  

---
## 1.2 Шаг production-прогноза

Использует уже обученную policy:

1. Чтение policy JSON  
2. Выбор модели для канал + метрика  
3. Выбор окна обучения  
4. Обучение на свежих данных  
5. Построение прогноза до конца месяца

---

# 2. Используемые данные

## 2.1 Источник факта

Данные загружаются из БД ClickHouse по измерениям:

- SALES_SUBSPECIES  - канал сбыта
- SIGN_IRIS - признак ассортимента
- FULL_SIGN (агрегат канала + IRIS) - просто конкантенация 2-х предыдущих

Используемые метрики:

- SUM_SNDS  - выручка с НДС
- SUM_PROFIT  - Прибывль
- SUM_PROFIT_NO_KSP  - Прибыль без скидки поставщика

---

## 2.2 Формирование длинного DataFrame

После выгрузки данные приводятся к универсальному виду:

Одна строка = одна метрика в один день:

| DDATE      | FULL_SIGN     | METRIC_NAME | METRIC_VALUE |
|------------|---------------|-------------|--------------|
| 2025-09-01 | КП РЕГИОН А   | SUM_SNDS    | 1200000      |

Такой формат позволяет:

- одинаково обучать любые модели  
- дополнять новыми метриками при необходимости  
- упрощать feature engineering 

---

# 3. Календарные признаки

После формирования long_df добавляются календарные признаки:

- DAY_OF_WEEK — день недели (0–6)
- DAY_OF_MONTH — день месяца
- MONTH — номер месяца
- WEEK_OF_YEAR — номер недели
- IS_WEEKEND — выходной день
- IS_HOLIDAY — праздник (из списка HOLIDAYS)
- START_OF_WEEK / END_OF_WEEK
- START_OF_MONTH / END_OF_MONTH
- MONTH_PROGRESS — прогресс месяца

Экзогенные Признаки используются для ML-моделей (задаются сразу до обучения и не меняются)

---

# 4. Lag и Rolling признаки

Для ML-моделей рассчитываются:

## 4.1 Лаги (сдвиг по дням 7, 14, 28 и тд)

- LAG_7D  
- LAG_14D  
- LAG_21D  
- LAG_28D  

## 4.2 Скользящие средние зв n-дней

- ROLL_MEAN_3  
- ROLL_MEAN_7  
- ROLL_MEAN_14  
- ROLL_MEAN_28  

---

# 5. Реестр моделей (MODEL_REGISTRY)

Все модели подключаются через единый registry.

Каждая модель обязана принимать:
df,
start_date,
end_date,
train_window_days,
full_sign,
metric_name

И возвращать DataFrame вида:
DDATE | FORECAST

---

## 5.1 Поддерживаемые модели

### Baseline

- BASELINE_OLS  
- BASELINE_EXPON  
- BASELINE_HOLT  
- BASELINE_HOLT_WINTERS  

### ML

- BASELINE_RF  
- CATBOOST_RECURSIVE  
- CATBOOST_DIRECT  
- LIGHTGBM_DIRECT  
- LIGHTGBM_RECURSIVE  
- XGB_DIRECT  

---

# 6. Логика бэктестирования

Backtest запускается по сетке:
Канал × Метрика × Модель × Train Window × Дата теста

Пример окон обучения:
TRAIN_WINDOWS = [60, 90, 120]

Пример дат теста:
Периоды внутри нескольких месяцев (например август–декабрь).

---

## 6.1 Алгоритм теста на одну дату

1. Берём тренировочное окно истории ДО даты старта прогноза: df[df["DDATE"] < START_FORECAST_DATE]
2. Обучается модель  
3. Строится прогноз до конца месяца  
4. Считается факт месяца  
5. Рассчитываются метрики  

---
# 7. Метрики качества

Рассчитываются:

- MAE  
- WMAPE  
- BIAS  

Основная метрика выбора модели — WMAPE_MONTH.

---
# 8. Автоматический выбор модели (Policy Learning)

После бэктестов формируется агрегированная таблица:
FULL_SIGN | METRIC_NAME | TRAIN_WINDOW_DAYS  | MODEL | WMAPE

---

## 8.1 Усреднение

WMAPE усредняется по всем датам бэктеста:

mean(WMAPE)

---

## 8.2 Выбор лучшей комбинации

Для каждой связки:
FULL_SIGN × METRIC_NAME

определяется:

- BEST_MODEL  
- BEST_WINDOW  
- BEST_MEAN_WMAPE  

---
# 9. Сохранение policy

Результат сохраняется в JSON:
Пример структуры:

```json
[
  {
    "FULL_SIGN": "Коммерческие продажи ЦФО БЕЗ ИРИС",
    "METRIC_NAME": "SUM_PROFIT",
    "BEST_MODEL": "CATBOOST_RECURSIVE",
    "BEST_WINDOW": 90
  }
]
```
---
## 10. Production-прогноз

При построении реального прогноза:

1. Загружается policy JSON
2. Для каждой связки определяется модель
3. Определяется train window
4. Берётся свежая история
5. Обучается модель

---
## 11. Рекурсивный прогноз

Основной production-подход — recursive forecasting.

Алгоритм:

Для каждого дня прогнозного периода:

1. Пересчитываются лаги
2. Обучается модель на train-окне
3. Прогнозируется 1 день
4. Прогноз подставляется как факт
5. Цикл повторяется до конца месяца

---
## 12. Итоговая схема работы

```
Загрузка данных
        ↓
Feature Engineering
        ↓
Backtests (модели × окна)
        ↓
    Метрики
        ↓
    Policy JSON
        ↓
Production Forecast
        ↓
Финальный прогноз
```
---
## 14. Как можно дальше улучшить

1. Сохранение обученных моделей
2. Автообновление policy
3. Ансамбль моделей
4. Feature store

****

